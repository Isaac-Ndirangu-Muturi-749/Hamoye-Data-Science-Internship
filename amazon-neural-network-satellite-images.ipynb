{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3384863",
   "metadata": {
    "_cell_guid": "5a58a9c4-482a-4dfc-8d5b-228c7024aa57",
    "_uuid": "0f5c91df-079a-458a-b82e-316725c27651",
    "papermill": {
     "duration": 0.007667,
     "end_time": "2023-11-21T05:35:22.510988",
     "exception": false,
     "start_time": "2023-11-21T05:35:22.503321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üåçüõ∞Ô∏è Planet: Understanding the Amazon from Space\n",
    "## Use satellite data to track the human footprint in the Amazon rainforest\n",
    "\n",
    "### Description\n",
    "üåçüõ∞Ô∏è Planet Aerial Imagery\n",
    "\n",
    "Every passing minute, an expanse of forest equivalent to 48 football fields disappears from our planet. The Amazon Basin takes the lead in this alarming deforestation trend, contributing to biodiversity loss, habitat destruction, climate change, and other catastrophic effects. Precise data on deforestation and human activities in forests is crucial for swift and effective responses from governments and local stakeholders.\n",
    "\n",
    "üõ∞Ô∏è Planet, the innovator behind the world‚Äôs largest fleet of Earth-imaging satellites, is set to capture daily imagery of the entire Earth's land surface at an impressive 3-5 meter resolution. While existing research focuses on monitoring forest changes, it often relies on coarse-resolution imagery from sources like Landsat (30-meter pixels) or MODIS (250-meter pixels), limiting its effectiveness in areas dominated by small-scale deforestation or forest degradation.\n",
    "\n",
    "Moreover, current methods struggle to distinguish between human-induced and natural forest loss. Higher resolution imagery, such as that from Planet, has demonstrated exceptional capability in this regard, but robust algorithms are yet to be developed.\n",
    "\n",
    "üåà In this competition, Planet and its Brazilian partner SCCON invite Kagglers to colorfully label satellite image chips with atmospheric conditions and various classes of land cover/land use. The resulting algorithms will empower the global community to comprehensively understand when, where, and why deforestation occurs worldwide‚Äîand, most importantly, how to respond effectively. üöÄ‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bf040f",
   "metadata": {
    "_cell_guid": "fc9a520f-5f08-402e-9bd6-9c2ceb3283ed",
    "_uuid": "92202b54-25d7-4430-809f-f0404d215f8f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-21T05:35:22.525848Z",
     "iopub.status.busy": "2023-11-21T05:35:22.525114Z",
     "iopub.status.idle": "2023-11-21T05:35:22.542895Z",
     "shell.execute_reply": "2023-11-21T05:35:22.541973Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.027829,
     "end_time": "2023-11-21T05:35:22.545426",
     "exception": false,
     "start_time": "2023-11-21T05:35:22.517597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['planet', 'test-jpg-additional']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = \"../input/planets-dataset/\"\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fceb2186",
   "metadata": {
    "_cell_guid": "2d7dd2cc-3d6c-4100-bae8-80f9f7a98646",
    "_uuid": "820d6870-62d1-4ead-9de6-2eb5586bfe06",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-21T05:35:22.560125Z",
     "iopub.status.busy": "2023-11-21T05:35:22.559591Z",
     "iopub.status.idle": "2023-11-21T05:35:22.633095Z",
     "shell.execute_reply": "2023-11-21T05:35:22.632162Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.083247,
     "end_time": "2023-11-21T05:35:22.635335",
     "exception": false,
     "start_time": "2023-11-21T05:35:22.552088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40474</th>\n",
       "      <td>train_40474</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40475</th>\n",
       "      <td>train_40475</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40476</th>\n",
       "      <td>train_40476</td>\n",
       "      <td>agriculture clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40477</th>\n",
       "      <td>train_40477</td>\n",
       "      <td>agriculture clear primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40478</th>\n",
       "      <td>train_40478</td>\n",
       "      <td>agriculture cultivation partly_cloudy primary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40479 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name                                           tags\n",
       "0          train_0                                   haze primary\n",
       "1          train_1                agriculture clear primary water\n",
       "2          train_2                                  clear primary\n",
       "3          train_3                                  clear primary\n",
       "4          train_4      agriculture clear habitation primary road\n",
       "...            ...                                            ...\n",
       "40474  train_40474                                  clear primary\n",
       "40475  train_40475                                         cloudy\n",
       "40476  train_40476                      agriculture clear primary\n",
       "40477  train_40477                 agriculture clear primary road\n",
       "40478  train_40478  agriculture cultivation partly_cloudy primary\n",
       "\n",
       "[40479 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_label = pd.read_csv(\"/kaggle/input/planets-dataset/planet/planet/train_classes.csv\")\n",
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "237be772",
   "metadata": {
    "_cell_guid": "398db6df-741f-48ee-8c66-129562b3158d",
    "_uuid": "5e885d69-fba3-4010-b7e1-515497015986",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-21T05:35:22.650826Z",
     "iopub.status.busy": "2023-11-21T05:35:22.650501Z",
     "iopub.status.idle": "2023-11-21T05:35:22.715765Z",
     "shell.execute_reply": "2023-11-21T05:35:22.714652Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.075555,
     "end_time": "2023-11-21T05:35:22.717947",
     "exception": false,
     "start_time": "2023-11-21T05:35:22.642392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['haze', 'agriculture', 'slash_burn', 'cloudy', 'conventional_mine', 'artisinal_mine', 'selective_logging', 'water', 'primary', 'clear', 'blow_down', 'road', 'bare_ground', 'habitation', 'blooming', 'partly_cloudy', 'cultivation']\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "\n",
    "def extract_unique_labels(tag_string):\n",
    "    '''\n",
    "    Takes in a string of tags, splits the tags, and stores them in a set\n",
    "    '''\n",
    "    [unique_labels.add(tag) for tag in tag_string.split()]\n",
    "\n",
    "# Create a copy of the train_label DataFrame\n",
    "train_data = train_label.copy()\n",
    "# Apply the function to extract unique labels from the 'tags' column\n",
    "train_data['tags'].apply(extract_unique_labels)\n",
    "# Convert the set of unique labels to a list\n",
    "unique_labels_list = list(unique_labels)\n",
    "# Display the list of unique labels\n",
    "print(unique_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b70945",
   "metadata": {
    "_cell_guid": "2ffe4e87-7be2-4032-851f-c926129689ed",
    "_uuid": "2eaca9b0-24cf-4641-ba6b-c35603c6ed0d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-21T05:35:22.732826Z",
     "iopub.status.busy": "2023-11-21T05:35:22.732525Z",
     "iopub.status.idle": "2023-11-21T05:35:23.359657Z",
     "shell.execute_reply": "2023-11-21T05:35:23.358715Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.637101,
     "end_time": "2023-11-21T05:35:23.361994",
     "exception": false,
     "start_time": "2023-11-21T05:35:22.724893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>haze</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>water</th>\n",
       "      <th>primary</th>\n",
       "      <th>clear</th>\n",
       "      <th>blow_down</th>\n",
       "      <th>road</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>habitation</th>\n",
       "      <th>blooming</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>cultivation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>haze primary</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1.jpg</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4.jpg</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40474</th>\n",
       "      <td>train_40474.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40475</th>\n",
       "      <td>train_40475.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40476</th>\n",
       "      <td>train_40476.jpg</td>\n",
       "      <td>agriculture clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40477</th>\n",
       "      <td>train_40477.jpg</td>\n",
       "      <td>agriculture clear primary road</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40478</th>\n",
       "      <td>train_40478.jpg</td>\n",
       "      <td>agriculture cultivation partly_cloudy primary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40479 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_name                                           tags  haze  \\\n",
       "0          train_0.jpg                                   haze primary     1   \n",
       "1          train_1.jpg                agriculture clear primary water     0   \n",
       "2          train_2.jpg                                  clear primary     0   \n",
       "3          train_3.jpg                                  clear primary     0   \n",
       "4          train_4.jpg      agriculture clear habitation primary road     0   \n",
       "...                ...                                            ...   ...   \n",
       "40474  train_40474.jpg                                  clear primary     0   \n",
       "40475  train_40475.jpg                                         cloudy     0   \n",
       "40476  train_40476.jpg                      agriculture clear primary     0   \n",
       "40477  train_40477.jpg                 agriculture clear primary road     0   \n",
       "40478  train_40478.jpg  agriculture cultivation partly_cloudy primary     0   \n",
       "\n",
       "       agriculture  slash_burn  cloudy  conventional_mine  artisinal_mine  \\\n",
       "0                0           0       0                  0               0   \n",
       "1                1           0       0                  0               0   \n",
       "2                0           0       0                  0               0   \n",
       "3                0           0       0                  0               0   \n",
       "4                1           0       0                  0               0   \n",
       "...            ...         ...     ...                ...             ...   \n",
       "40474            0           0       0                  0               0   \n",
       "40475            0           0       1                  0               0   \n",
       "40476            1           0       0                  0               0   \n",
       "40477            1           0       0                  0               0   \n",
       "40478            1           0       0                  0               0   \n",
       "\n",
       "       selective_logging  water  primary  clear  blow_down  road  bare_ground  \\\n",
       "0                      0      0        1      0          0     0            0   \n",
       "1                      0      1        1      1          0     0            0   \n",
       "2                      0      0        1      1          0     0            0   \n",
       "3                      0      0        1      1          0     0            0   \n",
       "4                      0      0        1      1          0     1            0   \n",
       "...                  ...    ...      ...    ...        ...   ...          ...   \n",
       "40474                  0      0        1      1          0     0            0   \n",
       "40475                  0      0        0      0          0     0            0   \n",
       "40476                  0      0        1      1          0     0            0   \n",
       "40477                  0      0        1      1          0     1            0   \n",
       "40478                  0      0        1      0          0     0            0   \n",
       "\n",
       "       habitation  blooming  partly_cloudy  cultivation  \n",
       "0               0         0              0            0  \n",
       "1               0         0              0            0  \n",
       "2               0         0              0            0  \n",
       "3               0         0              0            0  \n",
       "4               1         0              0            0  \n",
       "...           ...       ...            ...          ...  \n",
       "40474           0         0              0            0  \n",
       "40475           0         0              0            0  \n",
       "40476           0         0              0            0  \n",
       "40477           0         0              0            0  \n",
       "40478           0         0              1            1  \n",
       "\n",
       "[40479 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding for the labels in train classes\n",
    "for label in unique_labels_list:\n",
    "    train_data[label] = train_data['tags'].apply(lambda x: 1 if label in x.split() else 0)\n",
    "\n",
    "# Adding '.jpg' extension to the 'image_name' column for consistency with image file names\n",
    "train_data['image_name'] = train_data['image_name'].apply(lambda x: f'{x}.jpg')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6ee10c",
   "metadata": {
    "_cell_guid": "8a8d6a06-018a-419e-bcd3-9f179bd6e91a",
    "_uuid": "065a478d-6c33-42e7-809d-8deecc8faaf1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-21T05:35:23.378735Z",
     "iopub.status.busy": "2023-11-21T05:35:23.378338Z",
     "iopub.status.idle": "2023-11-21T05:35:23.385211Z",
     "shell.execute_reply": "2023-11-21T05:35:23.384211Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017366,
     "end_time": "2023-11-21T05:35:23.387201",
     "exception": false,
     "start_time": "2023-11-21T05:35:23.369835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['haze',\n",
       " 'agriculture',\n",
       " 'slash_burn',\n",
       " 'cloudy',\n",
       " 'conventional_mine',\n",
       " 'artisinal_mine',\n",
       " 'selective_logging',\n",
       " 'water',\n",
       " 'primary',\n",
       " 'clear',\n",
       " 'blow_down',\n",
       " 'road',\n",
       " 'bare_ground',\n",
       " 'habitation',\n",
       " 'blooming',\n",
       " 'partly_cloudy',\n",
       " 'cultivation']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the columns,i.e the labels that were newly added to the train_classes via hot encoding.\n",
    "columns = list(train_data.columns[2:])\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0ec9c02",
   "metadata": {
    "_cell_guid": "5a0f3265-5827-493c-ae77-e1e8136ef832",
    "_uuid": "2c76ce5f-21db-4d09-a652-7e8cabdd5926",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-21T05:35:23.403791Z",
     "iopub.status.busy": "2023-11-21T05:35:23.403465Z",
     "iopub.status.idle": "2023-11-21T05:41:11.113351Z",
     "shell.execute_reply": "2023-11-21T05:41:11.112333Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 347.892133,
     "end_time": "2023-11-21T05:41:11.286885",
     "exception": false,
     "start_time": "2023-11-21T05:35:23.394752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32384 validated image filenames.\n",
      "Found 8095 validated image filenames.\n",
      "Build model\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n",
      "Preview the model architecture\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 17)                8721      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,918,225\n",
      "Trainable params: 4,203,537\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "fitting our model using the parameters already defined\n",
      "2024/2024 [==============================] - 229s 109ms/step - loss: 0.1859 - multi_label_accuracy: 0.9286 - fbeta_score: 0.7478 - val_loss: 0.1560 - val_multi_label_accuracy: 0.9396 - val_fbeta_score: 0.7752\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=2, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Compute the F-beta score for multi-label classification.\n",
    "\n",
    "    Args:\n",
    "        y_true: Correct target values.\n",
    "        y_pred: Predicted values returned by the classifier.\n",
    "        beta: Beta value for weighting precision and recall.\n",
    "        epsilon: Small constant to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        F-beta score.\n",
    "    \"\"\"\n",
    "    beta_squared = beta**2\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), 0.5), tf.float32)\n",
    "\n",
    "    true_positive = tf.reduce_sum(y_true * y_pred, axis=1)\n",
    "    false_positive = tf.reduce_sum(y_pred, axis=1) - true_positive\n",
    "    false_negative = tf.reduce_sum(y_true, axis=1) - true_positive\n",
    "\n",
    "    precision = true_positive / (true_positive + false_positive + epsilon)\n",
    "    recall = true_positive / (true_positive + false_negative + epsilon)\n",
    "\n",
    "    fbeta = (1 + beta_squared) * precision * recall / (beta_squared * precision + recall + epsilon)\n",
    "    return fbeta\n",
    "\n",
    "\n",
    "def multi_label_accuracy(y_true, y_pred, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Compute accuracy for multi-label classification.\n",
    "\n",
    "    Args:\n",
    "        y_true: Correct target values.\n",
    "        y_pred: Predicted values returned by the classifier.\n",
    "        epsilon: Small constant to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        Accuracy score.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), 0.5), tf.float32)\n",
    "\n",
    "    true_positive = tf.reduce_sum(y_true * y_pred, axis=1)\n",
    "    false_positive = tf.reduce_sum(y_pred, axis=1) - true_positive\n",
    "    false_negative = tf.reduce_sum(y_true, axis=1) - true_positive\n",
    "\n",
    "    y_true_bool = tf.cast(y_true, tf.bool)\n",
    "    y_pred_bool = tf.cast(y_pred, tf.bool)\n",
    "\n",
    "    true_negative = tf.reduce_sum(tf.cast(~y_true_bool, tf.float32) * tf.cast(~y_pred_bool, tf.float32), axis=1)\n",
    "\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative + epsilon)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "def build_model():\n",
    "    # Use a pre-trained VGG16 model\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    \n",
    "    # Freeze the convolutional layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    predictions = Dense(17, activation='sigmoid')(x)\n",
    "    \n",
    "    # Create the final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = Adam(lr=1e-4)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[multi_label_accuracy, fbeta_score])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Model Checkpoint\n",
    "save_best_check_point = ModelCheckpoint(filepath='best_model.hdf5', \n",
    "                                        monitor='val_fbeta_score',\n",
    "                                        mode='max',\n",
    "                                        save_best_only=True,\n",
    "                                        save_weights_only=True)\n",
    "\n",
    "# Image Data Generator\n",
    "train_datagen = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
    "\n",
    "# Train Data Generator\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_data,\n",
    "                                                    directory=\"/kaggle/input/planets-dataset/planet/planet/train-jpg\",\n",
    "                                                    x_col=\"image_name\", y_col=columns, subset=\"training\",\n",
    "                                                    batch_size=16, seed=42, shuffle=True,\n",
    "                                                    class_mode=\"raw\", target_size=(128, 128))\n",
    "\n",
    "# Validation Data Generator\n",
    "val_generator = train_datagen.flow_from_dataframe(dataframe=train_data,\n",
    "                                                  directory=\"/kaggle/input/planets-dataset/planet/planet/train-jpg\",\n",
    "                                                  x_col=\"image_name\", y_col=columns, subset=\"validation\",\n",
    "                                                  batch_size=16, seed=42, shuffle=True,\n",
    "                                                  class_mode=\"raw\", target_size=(128, 128))\n",
    "\n",
    "# Step Sizes\n",
    "step_train_size = int(np.ceil(train_generator.samples / train_generator.batch_size))\n",
    "step_val_size = int(np.ceil(val_generator.samples / val_generator.batch_size))\n",
    "\n",
    "print('Build model') # Build Model\n",
    "model_1 = build_model()\n",
    "\n",
    "\n",
    "print('Preview the model architecture')# Preview the model architecture\n",
    "print(model_1.summary())\n",
    "print()\n",
    "\n",
    "print('fitting our model using the parameters already defined') #fitting our model using the parameters already defined \n",
    "history_1 = model_1.fit(\n",
    "    x = train_generator, \n",
    "    steps_per_epoch = step_train_size, \n",
    "    validation_data = val_generator, \n",
    "    validation_steps = step_val_size,\n",
    "    epochs = 1, \n",
    "    callbacks=[save_best_check_point]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dceedee",
   "metadata": {
    "_cell_guid": "b95c1a68-481e-405d-8134-c5bffea1db18",
    "_uuid": "7bd37d56-1260-4e4f-b856-b10e3205217a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-21T05:41:11.634588Z",
     "iopub.status.busy": "2023-11-21T05:41:11.633793Z",
     "iopub.status.idle": "2023-11-21T05:41:12.651742Z",
     "shell.execute_reply": "2023-11-21T05:41:12.650560Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.196104,
     "end_time": "2023-11-21T05:41:12.654622",
     "exception": false,
     "start_time": "2023-11-21T05:41:11.458518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  best_model.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b060ed74",
   "metadata": {
    "_cell_guid": "61b8b045-bb32-4d94-9762-9620e5b2ec8e",
    "_uuid": "79c627f7-1af4-4f10-888d-e123b66a888a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-21T05:41:13.090807Z",
     "iopub.status.busy": "2023-11-21T05:41:13.089911Z",
     "iopub.status.idle": "2023-11-21T05:49:09.799968Z",
     "shell.execute_reply": "2023-11-21T05:49:09.798860Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 476.962796,
     "end_time": "2023-11-21T05:49:09.802447",
     "exception": false,
     "start_time": "2023-11-21T05:41:12.839651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing a second model for predictions\n",
      "Loading the sample submission file\n",
      "Index(['image_name', 'tags'], dtype='object')\n",
      "\n",
      "Splitting the sample submission file into two parts\n",
      "Creating generator for test_df_part1\n",
      "Found 40669 validated image filenames.\n",
      "Making predictions on test_df_part1\n",
      "2542/2542 [==============================] - 216s 85ms/step\n",
      "           image_name                   tags\n",
      "0          test_0.jpg          primary clear\n",
      "1          test_1.jpg          primary clear\n",
      "2          test_2.jpg  primary partly_cloudy\n",
      "3          test_3.jpg          primary clear\n",
      "4          test_4.jpg  primary partly_cloudy\n",
      "...               ...                    ...\n",
      "40664  test_40664.jpg          primary clear\n",
      "40665  test_40665.jpg          primary clear\n",
      "40666  test_40666.jpg          primary clear\n",
      "40667  test_40667.jpg  primary partly_cloudy\n",
      "40668  test_40668.jpg          primary clear\n",
      "\n",
      "[40669 rows x 2 columns]\n",
      "\n",
      "Additional test dataset\n",
      "Creating generator for test_df_part2\n",
      "Found 20522 validated image filenames.\n",
      "Making predictions on test_df_part2\n",
      "1283/1283 [==============================] - 111s 86ms/step\n",
      "          image_name                                       tags\n",
      "0         test_0.jpg                              primary clear\n",
      "1         test_1.jpg                              primary clear\n",
      "2         test_2.jpg                      primary partly_cloudy\n",
      "3         test_3.jpg                              primary clear\n",
      "4         test_4.jpg                      primary partly_cloudy\n",
      "...              ...                                        ...\n",
      "61186  file_9995.jpg                      primary partly_cloudy\n",
      "61187  file_9996.jpg                        water primary clear\n",
      "61188  file_9997.jpg                              primary clear\n",
      "61189  file_9998.jpg                                     cloudy\n",
      "61190  file_9999.jpg  agriculture primary clear road habitation\n",
      "\n",
      "[61191 rows x 2 columns]\n",
      "\n",
      "Save the final result to a CSV file\n"
     ]
    }
   ],
   "source": [
    "print('Initializing a second model for predictions')\n",
    "# Initializing a second model for predictions\n",
    "model_for_predictions = build_model()\n",
    "model_for_predictions.load_weights('best_model.hdf5')\n",
    "\n",
    "print('Loading the sample submission file')\n",
    "# Loading the sample submission file\n",
    "sample_submission = pd.read_csv('/kaggle/input/planets-dataset/planet/planet/sample_submission.csv')\n",
    "# Adding '.jpg' extension to image names in the sample submission file\n",
    "sample_submission['image_name'] = sample_submission['image_name'].apply(lambda x: '{}.jpg'.format(x))\n",
    "# Print column names in the sample_submission DataFrame\n",
    "print(sample_submission.columns)\n",
    "print()\n",
    "\n",
    "print('Splitting the sample submission file into two parts')\n",
    "# Splitting the sample submission file into two parts\n",
    "test_df_part1 = sample_submission.iloc[:40669][['image_name']].reset_index(drop=True)\n",
    "test_df_part2 = sample_submission.iloc[40669:][['image_name']].reset_index(drop=True)\n",
    "\n",
    "print('Creating generator for test_df_part1')\n",
    "# Initialize ImageDataGenerator for the test images and perform rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "# Create a generator for the images in the first part of the test dataset\n",
    "test_generator_part1 = test_datagen.flow_from_dataframe(dataframe=test_df_part1,\n",
    "                                                          directory=\"/kaggle/input/planets-dataset/planet/planet/test-jpg\",\n",
    "                                                          x_col=\"image_name\",\n",
    "                                                          y_col=None,\n",
    "                                                          batch_size=16,\n",
    "                                                          shuffle=False,\n",
    "                                                          class_mode=None,\n",
    "                                                          target_size=(128, 128))\n",
    "\n",
    "# Get the number of steps for the test generator\n",
    "step_test_size_part1 = int(np.ceil(test_generator_part1.samples / test_generator_part1.batch_size))\n",
    "# Reset the test generator to avoid shuffling of indices\n",
    "test_generator_part1.reset()\n",
    "# Make predictions on the first part of the test dataset\n",
    "# Make predictions on the first part of the test dataset\n",
    "print('Making predictions on test_df_part1')\n",
    "pred_part1 = model_for_predictions.predict(test_generator_part1, steps=step_test_size_part1, verbose=1)\n",
    "# Get the filenames in the generator using the attribute .filenames\n",
    "file_names_part1 = test_generator_part1.filenames  # Fixed the missing parenthesis here\n",
    "# Convert predicted values to a DataFrame and join labels together if the probability is greater than 0.5\n",
    "pred_tags_part1 = pd.DataFrame(pred_part1)\n",
    "pred_tags_part1 = pred_tags_part1.apply(lambda x: ' '.join(np.array(unique_labels_list)[x > 0.5]), axis=1)\n",
    "# Create a DataFrame for the first set of predictions\n",
    "result_part1 = pd.DataFrame({'image_name': file_names_part1, 'tags': pred_tags_part1})\n",
    "print(result_part1)\n",
    "print()\n",
    "\n",
    "                                           \n",
    "print('Additional test dataset')# Additional test dataset\n",
    "test_df_part2 = sample_submission.iloc[40669:][['image_name']].reset_index(drop=True)\n",
    "# Create a generator for the additional test image files\n",
    "print('Creating generator for test_df_part2')\n",
    "test_generator_part2 = test_datagen.flow_from_dataframe(dataframe=test_df_part2,\n",
    "                                                          directory=\"/kaggle/input/planets-dataset/test-jpg-additional/test-jpg-additional\",\n",
    "                                                          x_col=\"image_name\",\n",
    "                                                          y_col=None,\n",
    "                                                          batch_size=16,\n",
    "                                                          shuffle=False,\n",
    "                                                          class_mode=None,\n",
    "                                                          target_size=(128, 128))\n",
    "\n",
    "# Get the number of steps for the additional test generator\n",
    "step_test_size_part2 = int(np.ceil(test_generator_part2.samples / test_generator_part2.batch_size))\n",
    "# Reset the additional test generator to avoid shuffling of indices\n",
    "test_generator_part2.reset()\n",
    "# Make predictions on the additional test dataset\n",
    "print('Making predictions on test_df_part2')\n",
    "add_pred_part2 = model_for_predictions.predict(test_generator_part2, steps=step_test_size_part2, verbose=1)\n",
    "# Get the filenames in the generator using the attribute .filenames\n",
    "file_names_part2 = test_generator_part2.filenames\n",
    "# Convert predicted values to a DataFrame and join labels together if the probability is greater than 0.5\n",
    "add_pred_tags_part2 = pd.DataFrame(add_pred_part2)\n",
    "add_pred_tags_part2 = add_pred_tags_part2.apply(lambda x: ' '.join(np.array(unique_labels_list)[x > 0.5]), axis=1)\n",
    "# Create a DataFrame for the second set of predictions\n",
    "result_part2 = pd.DataFrame({'image_name': file_names_part2, 'tags': add_pred_tags_part2})\n",
    "\n",
    "# Concatenate the results in order to avoid shuffling the index\n",
    "final_result = pd.concat([result_part1, result_part2]).reset_index(drop=True)\n",
    "print(final_result)\n",
    "print()\n",
    "                                           \n",
    "print('Save the final result to a CSV file')\n",
    "# Save the final result to a CSV file\n",
    "final_result.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe2209a3",
   "metadata": {
    "_cell_guid": "1d5c6408-af97-41c9-840c-b41bb8aa01ad",
    "_uuid": "df4a80c6-8edf-4c1c-b2a5-ce64d35e1d26",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-21T05:49:10.776478Z",
     "iopub.status.busy": "2023-11-21T05:49:10.775625Z",
     "iopub.status.idle": "2023-11-21T05:49:11.760398Z",
     "shell.execute_reply": "2023-11-21T05:49:11.759358Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.449048,
     "end_time": "2023-11-21T05:49:11.762924",
     "exception": false,
     "start_time": "2023-11-21T05:49:10.313876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  best_model.hdf5  submission_1.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb8d91c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T05:49:12.738916Z",
     "iopub.status.busy": "2023-11-21T05:49:12.737861Z",
     "iopub.status.idle": "2023-11-21T05:49:15.693928Z",
     "shell.execute_reply": "2023-11-21T05:49:15.692735Z"
    },
    "papermill": {
     "duration": 3.433794,
     "end_time": "2023-11-21T05:49:15.696353",
     "exception": false,
     "start_time": "2023-11-21T05:49:12.262559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_1.csv\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir /kaggle/working/output\n",
    "!mv submission_1.csv /kaggle/working/output/\n",
    "!ls /kaggle/working/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d22f80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T05:49:16.676484Z",
     "iopub.status.busy": "2023-11-21T05:49:16.675449Z",
     "iopub.status.idle": "2023-11-21T05:49:16.680737Z",
     "shell.execute_reply": "2023-11-21T05:49:16.679650Z"
    },
    "papermill": {
     "duration": 0.519332,
     "end_time": "2023-11-21T05:49:16.682995",
     "exception": false,
     "start_time": "2023-11-21T05:49:16.163663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir /kaggle/working/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8deefab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T05:49:17.665521Z",
     "iopub.status.busy": "2023-11-21T05:49:17.665115Z",
     "iopub.status.idle": "2023-11-21T05:49:18.993116Z",
     "shell.execute_reply": "2023-11-21T05:49:18.991890Z"
    },
    "papermill": {
     "duration": 1.811689,
     "end_time": "2023-11-21T05:49:18.995731",
     "exception": false,
     "start_time": "2023-11-21T05:49:17.184042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/kaggle\", line 5, in <module>\r\n",
      "    from kaggle.cli import main\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/kaggle/__init__.py\", line 23, in <module>\r\n",
      "    api.authenticate()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\r\n",
      "    self.config_file, self.config_dir))\r\n",
      "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle kernels output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be62dad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T05:49:19.997500Z",
     "iopub.status.busy": "2023-11-21T05:49:19.996280Z",
     "iopub.status.idle": "2023-11-21T05:49:20.001932Z",
     "shell.execute_reply": "2023-11-21T05:49:20.000890Z"
    },
    "papermill": {
     "duration": 0.527147,
     "end_time": "2023-11-21T05:49:20.004215",
     "exception": false,
     "start_time": "2023-11-21T05:49:19.477068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !set KAGGLE_USERNAME=isaacndirangumuturi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4c84a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T05:49:20.931909Z",
     "iopub.status.busy": "2023-11-21T05:49:20.931032Z",
     "iopub.status.idle": "2023-11-21T05:49:20.936093Z",
     "shell.execute_reply": "2023-11-21T05:49:20.935071Z"
    },
    "papermill": {
     "duration": 0.469899,
     "end_time": "2023-11-21T05:49:20.938272",
     "exception": false,
     "start_time": "2023-11-21T05:49:20.468373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !set KAGGLE_KEY=25f1399d14d29fd98551b2c740607112\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e42f2e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T05:49:21.865870Z",
     "iopub.status.busy": "2023-11-21T05:49:21.865078Z",
     "iopub.status.idle": "2023-11-21T05:49:21.869484Z",
     "shell.execute_reply": "2023-11-21T05:49:21.868423Z"
    },
    "papermill": {
     "duration": 0.47137,
     "end_time": "2023-11-21T05:49:21.871761",
     "exception": false,
     "start_time": "2023-11-21T05:49:21.400391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !kaggle datasets list\n",
    "# !kaggle competitions list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcaf9965",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T05:49:22.848158Z",
     "iopub.status.busy": "2023-11-21T05:49:22.847412Z",
     "iopub.status.idle": "2023-11-21T05:49:22.852221Z",
     "shell.execute_reply": "2023-11-21T05:49:22.851138Z"
    },
    "papermill": {
     "duration": 0.471391,
     "end_time": "2023-11-21T05:49:22.854449",
     "exception": false,
     "start_time": "2023-11-21T05:49:22.383058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.environ['KAGGLE_USERNAME'] = isaacndirangumuturi\n",
    "# os.environ['KAGGLE_KEY'] = 25f1399d14d29fd98551b2c740607112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35d96ce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T05:49:23.784969Z",
     "iopub.status.busy": "2023-11-21T05:49:23.784564Z",
     "iopub.status.idle": "2023-11-21T05:49:23.789059Z",
     "shell.execute_reply": "2023-11-21T05:49:23.788032Z"
    },
    "papermill": {
     "duration": 0.473844,
     "end_time": "2023-11-21T05:49:23.791199",
     "exception": false,
     "start_time": "2023-11-21T05:49:23.317355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls /root/.kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec58f9",
   "metadata": {
    "papermill": {
     "duration": 0.459665,
     "end_time": "2023-11-21T05:49:24.759236",
     "exception": false,
     "start_time": "2023-11-21T05:49:24.299571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 868312,
     "sourceId": 6322,
     "sourceType": "competition"
    },
    {
     "datasetId": 503255,
     "sourceId": 938046,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30408,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 856.499892,
   "end_time": "2023-11-21T05:49:28.515658",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-21T05:35:12.015766",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
